{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9898956,"sourceType":"datasetVersion","datasetId":6080607},{"sourceId":9239705,"sourceType":"datasetVersion","datasetId":5589028},{"sourceId":9239691,"sourceType":"datasetVersion","datasetId":5589019},{"sourceId":9239712,"sourceType":"datasetVersion","datasetId":5589033},{"sourceId":9226750,"sourceType":"datasetVersion","datasetId":5580434}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:48:50.236796Z","iopub.execute_input":"2024-11-15T14:48:50.237314Z","iopub.status.idle":"2024-11-15T14:48:50.270560Z","shell.execute_reply.started":"2024-11-15T14:48:50.237254Z","shell.execute_reply":"2024-11-15T14:48:50.269060Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install dask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:30:43.673632Z","iopub.execute_input":"2024-11-14T14:30:43.674095Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: dask in /opt/conda/lib/python3.10/site-packages (2024.9.1)\nRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask) (8.1.7)\nRequirement already satisfied: cloudpickle>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from dask) (3.0.0)\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask) (2024.6.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from dask) (21.3)\nRequirement already satisfied: partd>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from dask) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask) (6.0.2)\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask) (0.12.1)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask) (7.0.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask) (3.19.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->dask) (3.1.2)\nRequirement already satisfied: locket in /opt/conda/lib/python3.10/site-packages (from partd>=1.4.0->dask) (1.0.0)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"#Импорт библиотек\nimport dask.dataframe as dd\nimport pandas as pd\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:48:52.556796Z","iopub.execute_input":"2024-11-15T14:48:52.557671Z","iopub.status.idle":"2024-11-15T14:48:54.211900Z","shell.execute_reply.started":"2024-11-15T14:48:52.557624Z","shell.execute_reply":"2024-11-15T14:48:54.210689Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Запись файлов\nattr = dd.read_parquet('/kaggle/input/attributes/attributes.parquet')\ntrain = dd.read_parquet('/kaggle/input/train-data/train.parquet')\n\n#Смена типа данных для сокращения требуемого объёма памяти\nattr['variantid'] = attr['variantid'].astype('int32')\ntrain['variantid1'] = train['variantid1'].astype('int32')\ntrain['variantid2'] = train['variantid2'].astype('int32')\n\n#Деление на классы и формирование сбалансированной выборки\nclass_0 = train[train['target'] == 0]\nclass_1 = train[train['target'] == 1]\n\nn_class_0 = min(2500, class_0.shape[0].compute())\nn_class_1 = min(2500, class_1.shape[0].compute())\nn = train.shape[0].compute()\n\ndel train\n\nsample_class_0 = class_0.sample(frac=n_class_0/n, random_state=42)\nsample_class_1 = class_1.sample(frac=n_class_1/n, random_state=42)\n\nbalanced_sample = dd.concat([sample_class_0, sample_class_1])\n\n#Выбор необходимых значений из attr\nvariant_ids = dd.concat([balanced_sample['variantid1'], balanced_sample['variantid2']]).unique()\nvariant_ids = variant_ids.compute().values\nattr = attr[attr['variantid'].isin(variant_ids)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:48:59.281460Z","iopub.execute_input":"2024-11-15T14:48:59.282887Z","iopub.status.idle":"2024-11-15T14:49:00.430494Z","shell.execute_reply.started":"2024-11-15T14:48:59.282834Z","shell.execute_reply":"2024-11-15T14:49:00.429183Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"При анализе данных, представленных в файле attributes.parquet, было выявлено, что в столбце characteristic_attributes_mapping содержится 6016 атрибутов с различными названиями, однако некоторые из них несут одинаковый смысл, несмотря на отличия в формулировке (после попытки объединения осталось порядка 4000 атрибутов, поэтому было принято решение выделить наиболее часто встречающиеся из них в отдельные столбцы - цвет, бренд, тип и страну, а оставшиеся векторизовать).","metadata":{}},{"cell_type":"code","source":"#Преобразование строки JSON в объект Python\nattr['attributes_dicts'] = attr['characteristic_attributes_mapping'].map_partitions(lambda x: x.apply(json.loads), meta=('x', 'object'))\n\n#Выделение наиболее часто встречающихся атрибутов в отдельные столбцы\ndef extract_attributes(attrs):\n    color = None\n    brand = None\n    type_ = None\n    country = None\n    for key in attrs.keys():\n        if 'Цвет' in key:\n            color = attrs.get(key)[0].lower()\n        if 'Бренд' in key or 'Издательство' in key:\n            brand = attrs.get(key)[0].lower()\n        if 'Тип' in key:\n            type_ = attrs.get(key)[0].lower()\n        if 'Страна' in key or 'Изготовитель' in key:\n            country = attrs.get(key)[0]\n    return pd.Series({'color': color, 'brand': brand, 'type': type_, 'country': country})\n\nattr[['color', 'brand', 'type', 'country']] = attr['attributes_dicts'].map_partitions(lambda x: x.apply(extract_attributes), meta={'color': 'object', 'brand': 'object', 'type': 'object', 'country': 'object'})\n\n#Вынесение в отдельные столбцы информации о категориях 2 и 4 уровня\nattr['cat2'] = attr['categories'].map_partitions(lambda x: x.apply(lambda y: json.loads(y).get('2')), meta=('x', 'object'))\nattr['cat4'] = attr['categories'].map_partitions(lambda x: x.apply(lambda y: json.loads(y).get('4')), meta=('x', 'object'))\nattr = attr.drop(['categories'], axis = 1)\n\n#Запись в переменные файлов с эмбеддингами\nemb = dd.read_parquet('/kaggle/input/resnet50embeddings/resnet.parquet', columns = ['variantid', 'main_pic_embeddings_resnet_v1'])\ntext = dd.read_parquet('/kaggle/input/text-and-bert/text_and_bert.parquet', columns = ['variantid', 'description', 'name_bert_64'])\n\n#Смена типа данных для сокращения требуемого объёма памяти\nemb['variantid'] = emb['variantid'].astype('int32')\ntext['variantid'] = text['variantid'].astype('int32')\n\n#Добавление новой информации к данным о категориях и атрибутах\nattr = dd.merge(attr, emb, on='variantid', how='left')\ndel emb\nattr = dd.merge(attr, text, on='variantid', how='left')\ndel text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:03.750834Z","iopub.execute_input":"2024-11-15T14:49:03.751421Z","iopub.status.idle":"2024-11-15T14:49:03.870660Z","shell.execute_reply.started":"2024-11-15T14:49:03.751367Z","shell.execute_reply":"2024-11-15T14:49:03.869351Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Нижепредставленный закомментированный код изначально планировалось использовать для выделения нескольких дополнительных признаков для обучения модели, например количества одинаковых атрибутов у двух сравниваемых товаров, однако впоследствии было решено сравнивать лишь эмбединги, полученные из строки атрибутов.","metadata":{}},{"cell_type":"code","source":"'''\nimport gc\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n#Определение всех возможных названий атрибутов товаров для дальнейшего объединения схожих\nunique_attrib = set()\nfor dict_ in attr['attributes_dicts']:\n    unique_attrib.update(dict_.keys())\n    \nunique_attrib = list(unique_attrib)\n\n#Создание словаря сопоставления для объединения наименований схожих атрибутов через векторизацию и расчёт косинусного расстояния\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(unique_attrib)\n\nthreshold = 0.8\ncosine_sim = cosine_similarity(tfidf_matrix)\n\nattribute_mapping = {}\nfor i in range(len(cosine_sim)):\n    for j in range(i + 1, len(cosine_sim)):\n        if cosine_sim[i][j] > threshold:\n            attribute_mapping.setdefault(unique_attrib[i], []).append(unique_attrib[j])\n\n#Создание обратного сопоставления для замены\nreverse_mapping = {}\nfor key, values in attribute_mapping.items():\n    for value in values:\n        reverse_mapping[value] = key\n        \n#Замена значений в датафрейме\ndef replace_attribute_keys(attribute_dict):\n    return {reverse_mapping.get(key, key): value for key, value in attribute_dict.items()}\n\nattr['attributes_dicts'] = attr['attributes_dicts'].map_partitions(lambda x: x.apply(replace_attribute_keys, meta=('x', 'object')))\n\n#Освобождение памяти\ndel attribute_mapping\ndel reverse_mapping\ngc.collect()\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:10.358003Z","iopub.execute_input":"2024-11-14T14:20:10.358496Z","iopub.status.idle":"2024-11-14T14:20:46.384162Z","shell.execute_reply.started":"2024-11-14T14:20:10.358451Z","shell.execute_reply":"2024-11-14T14:20:46.382481Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import init\nfrom transformers import AutoTokenizer, AutoModel\nfrom dataclasses import dataclass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:13.810273Z","iopub.execute_input":"2024-11-15T14:49:13.810732Z","iopub.status.idle":"2024-11-15T14:49:19.293770Z","shell.execute_reply.started":"2024-11-15T14:49:13.810690Z","shell.execute_reply":"2024-11-15T14:49:19.292468Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#Код для получения эмбеддингов из строк\nclass ProdFeatureEncoder(nn.Module):\n    \"\"\"\n    Model for creating embeddings with pre-trained ruBERT-tiny BERT.\n\n    Attributes:\n        config (object): Configuration object containing model hyperparameters.\n        tokenizer (AutoTokenizer): Tokenizer instance for ruBERT-tiny.\n        model (AutoModel): Pre-trained ruBERT-tiny model instance.\n        fc (nn.Linear): Linear layer for dimensionality reduction.\n    \"\"\"\n    def __init__(self, config):\n        \"\"\"\n        Initializes the ProdFeatureEncoder model.\n\n        Args:\n            config (object): Configuration object containing model hyperparameters.\n        \"\"\"\n        super().__init__()\n        self.config = config\n        self.tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/rubert-tiny\")\n        self.model = AutoModel.from_pretrained(\"/kaggle/input/rubert-tiny\")\n        self.fc = nn.Linear(self.config.bert_output_size, self.config.embedding_size)\n        init.xavier_uniform_(self.fc.weight)\n        self.norm = nn.LayerNorm(self.config.embedding_size)\n\n    def forward(self, text: str):\n        \"\"\"\n        Creates an embedding for the input text.\n        Args:\n            text (str): Input text to create an embedding for.\n        Returns:\n            torch.Tensor: Embedding vector for the input text.\n        \"\"\"\n        tokens = self.tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n        model_output = self.model(**{k: v.to(self.model.device) for k, v in tokens.items()})\n        embedding = model_output.last_hidden_state[:, 0, :]\n        embedding = self.fc(embedding)\n        return embedding[0]\n\n@dataclass\nclass ModelConfig:\n    bert_output_size = 312\n    embedding_size = 128\n\ndef encodering(line):\n    encoded_input=encoder(line)\n    return encoded_input.clone().detach().numpy()\n\ndef apply_encodering(series):\n    return series.map(lambda x: encodering(x) if x is not None and not pd.isna(x) else None, meta=('x', 'object'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:25.622912Z","iopub.execute_input":"2024-11-15T14:49:25.623688Z","iopub.status.idle":"2024-11-15T14:49:25.640480Z","shell.execute_reply.started":"2024-11-15T14:49:25.623638Z","shell.execute_reply":"2024-11-15T14:49:25.639005Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model_config = ModelConfig()\nencoder = ProdFeatureEncoder(model_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:29.932893Z","iopub.execute_input":"2024-11-15T14:49:29.933418Z","iopub.status.idle":"2024-11-15T14:49:31.434072Z","shell.execute_reply.started":"2024-11-15T14:49:29.933367Z","shell.execute_reply":"2024-11-15T14:49:31.432754Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"attr['characteristic_attributes_mapping'] = apply_encodering(attr['characteristic_attributes_mapping'])\nattr['color'] = apply_encodering(attr['color'])\nattr['type'] = apply_encodering(attr['type'])\nattr['cat2'] = apply_encodering(attr['cat2'])\nattr['cat4'] = apply_encodering(attr['cat4'])\nattr['description'] = apply_encodering(attr['description'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:38.322250Z","iopub.execute_input":"2024-11-15T14:49:38.323037Z","iopub.status.idle":"2024-11-15T14:49:42.614252Z","shell.execute_reply.started":"2024-11-15T14:49:38.322947Z","shell.execute_reply":"2024-11-15T14:49:42.613081Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from scipy.spatial.distance import cosine\n\n#Объединение с тренировочным датафреймом\nmerged_df = dd.merge(balanced_sample, attr.add_suffix('1'), on='variantid1', how='inner')\nmerged_df = dd.merge(merged_df, attr.add_suffix('2'), on='variantid2', how='inner')\n\n'''\n#Определение количества одинаковых наименований атрибутов для пар товаров\ndef count_common_keys(row):\n    keys1 = row['attributes_dicts1'].keys()\n    keys2 = row['attributes_dicts2'].keys()\n    return len(set(keys1) & set(keys2))\n\nmerged_df['count_of_eq_attr'] = merged_df.apply(count_common_keys, axis=1)\n'''\n\n#Получение столбцов со сравнением признаков пары товаров\nmerged_df['brand_eq'] = (merged_df['brand1'] == merged_df['brand2']).astype(int)\nmerged_df['country_eq'] = (merged_df['country1'] == merged_df['country2']).astype(int)\n\n#Функция для вычисления косинусного расстояния\ndef compute_cosine_distance(v1, v2):\n    if v1 is None or v2 is None:\n        return None\n    return cosine(v1, v2)\n\n#Функция для расчета манхэттенского расстояния\ndef manhattan_distance(vec1, vec2):\n    return sum(abs(a - b) for a, b in zip(vec1, vec2))\n\n#Расчёт косинусных расстояний\nmerged_df['attr_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['characteristic_attributes_mapping1'], row['characteristic_attributes_mapping2']), axis=1), meta=('x', 'f8'))\nmerged_df['color_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['color1'], row['color2']), axis=1), meta=('x', 'f8'))\nmerged_df['type_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['type1'], row['type2']), axis=1), meta=('x', 'f8'))\nmerged_df['cat2_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['cat21'], row['cat22']), axis=1), meta=('x', 'f8'))\nmerged_df['cat4_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['cat41'], row['cat42']), axis=1), meta=('x', 'f8'))\nmerged_df['pic_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: manhattan_distance(row['main_pic_embeddings_resnet_v11'][0], row['main_pic_embeddings_resnet_v12'][0]), axis=1), meta=('x', 'f8'))\nmerged_df['description_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['description1'], row['description2']), axis=1), meta=('x', 'f8'))\nmerged_df['name_dis'] = merged_df.map_partitions(lambda df: df.apply(lambda row: compute_cosine_distance(row['name_bert_641'], row['name_bert_642']), axis=1), meta=('x', 'f8'))\n\n#Удаление ненужных столбцов\ncolumns_to_drop = ['variantid1', 'variantid2', 'brand1', 'brand2', 'country1', 'country2', 'attributes_dicts1', 'attributes_dicts2']\n\nmerged_df = merged_df.drop(columns=columns_to_drop)\n\nmerged_df = merged_df.persist()\nmerged_df = merged_df.compute()\n\nmerged_df.to_parquet('/kaggle/working/merged_df.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T14:49:46.762046Z","iopub.execute_input":"2024-11-15T14:49:46.762492Z","iopub.status.idle":"2024-11-15T15:15:01.411335Z","shell.execute_reply.started":"2024-11-15T14:49:46.762451Z","shell.execute_reply":"2024-11-15T15:15:01.409864Z"}},"outputs":[],"execution_count":10}]}